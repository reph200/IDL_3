import matplotlib.pyplot as plt

# Training and testing loss values for each step (you can replace these with actual values)
train_loss_values = [0.6917, 0.7264, 0.7082, 0.6481, 0.5921, 0.3812, 0.5143, 0.6029, 0.5134, 0.3539,
                     0.4864, 0.5028, 0.5193, 0.4193, 0.4222, 0.4416, 0.3730, 0.4085, 0.4064, 0.3458,
                     0.5580, 0.4788, 0.4776, 0.3931, 0.4079, 0.4554, 0.4088, 0.5218, 0.4401, 0.3877,
                     0.4378, 0.2644, 0.4050, 0.4639, 0.4661, 0.5186, 0.5455, 0.4447, 0.5228, 0.3905,
                     0.4397, 0.4256, 0.5745, 0.2134, 0.3706, 0.3503, 0.4391, 0.3806, 0.3396, 0.4532,
                     0.2989, 0.3696, 0.2922, 0.6214, 0.3227, 0.2646, 0.2957, 0.3884, 0.3646, 0.2539,
                     0.3291, 0.3366, 0.3804, 0.3496, 0.3920, 0.1957, 0.3064, 0.2474, 0.1336, 0.3834,
                     0.5201, 0.3663, 0.6593, 0.3602, 0.3189, 0.3833, 0.2512, 0.4933, 0.5066, 0.3519,
                     0.3748, 0.1842, 0.2624, 0.2723, 0.3414, 0.2871, 0.2495, 0.3363, 0.3774, 0.3015,
                     0.4798, 0.4215, 0.2343, 0.3256, 0.2573, 0.2337, 0.2864, 0.2555, 0.2124, 0.2247,
                     0.8293, 0.2917, 0.3685, 0.2444, 0.2584, 0.2286, 0.2448, 0.3391, 0.2185, 0.3075,
                     0.3084, 0.1766, 0.2745, 0.3075, 0.3602, 0.3363, 0.2124, 0.3588, 0.3774, 0.2437]

test_loss_values = [0.7543, 0.7042, 0.6974, 0.6236, 0.6545, 0.5435, 0.5396, 0.5861, 0.4805, 0.4998,
                    0.4928, 0.5821, 0.4870, 0.4833, 0.5370, 0.4656, 0.5552, 0.5931, 0.4928, 0.3647,
                    0.4844, 0.4524, 0.3381, 0.3588, 0.4895, 0.3880, 0.3845, 0.5133, 0.5951, 0.4109,
                    0.4751, 0.3168, 0.2778, 0.4915, 0.4867, 0.2867, 0.3501, 0.5246, 0.3542, 0.3289,
                    0.3083, 0.2984, 0.3807, 0.3098, 0.2540, 0.2355, 0.3154, 0.3052, 0.3092, 0.3135,
                    0.3721, 0.5387, 0.3355, 0.2576, 0.4696, 0.5477, 0.4298, 0.3056, 0.4097, 0.4309,
                    0.4452, 0.4309, 0.3723, 0.4213, 0.2556, 0.3751, 0.5680, 0.4828, 0.4431, 0.4730,
                    0.3355, 0.2576, 0.2826, 0.3273, 0.4503, 0.5268, 0.5690, 0.4414, 0.3833, 0.3849,
                    0.4850, 0.3393, 0.5045, 0.5180, 0.4746, 0.3940, 0.5033, 0.3164, 0.3604, 0.2296,
                    0.5000, 0.2789, 0.3504, 0.1771, 0.3297, 0.4199, 0.2617, 0.4490, 0.3045, 0.3716,
                    0.2998, 0.4180, 0.4224, 0.4762, 0.3407, 0.2578, 0.3735, 0.5742, 0.3787, 0.4006,
                    0.4633, 0.4615, 0.4157, 0.4006, 0.3273, 0.3164, 0.3045, 0.2984, 0.3187, 0.2437]

# Training and testing accuracy values for each step (you can replace these with actual values)
train_accuracy_values = [0.5000, 0.3438, 0.4375, 0.5625, 0.6562, 0.8125, 0.7500, 0.6562, 0.7812, 0.8750,
                         0.7812, 0.7188, 0.7188, 0.8438, 0.8438, 0.7500, 0.8125, 0.7500, 0.7812, 0.8125,
                         0.7812, 0.7500, 0.7812, 0.7500, 0.8125, 0.7812, 0.8750, 0.7500, 0.9062, 0.8125,
                         0.8125, 0.8750, 0.7500, 0.8125, 0.8125, 0.7500, 0.7188, 0.7812, 0.8125, 0.7812,
                         0.8438, 0.8438, 0.7812, 0.9062, 0.8750, 0.8750, 0.7812, 0.7812, 0.9062, 0.8125,
                         0.9062, 0.8750, 0.9062, 0.8438, 0.7812, 0.8125, 0.8750, 0.8438, 0.8438, 0.8125,
                         0.7812, 0.9062, 0.9062, 0.9062, 0.8438, 0.9062, 0.7812, 0.7812, 0.8750, 0.8125,
                         0.8125, 0.8750, 0.8750, 0.9062, 0.9062, 0.9375, 0.7812, 0.9375, 0.8750, 0.8750,
                         0.9062, 0.9688, 0.8125, 0.8125, 0.8125, 0.8125, 0.9062, 0.8750, 0.8125, 0.8750,
                         0.8750, 0.8750, 0.8125, 0.8125, 0.9062, 0.8750, 0.9062, 0.8125, 0.8125, 0.9375,
                         0.8125, 0.8750, 0.9062, 0.9062, 0.8125, 0.9062, 0.8438, 0.8125, 0.9062, 0.9375,
                         0.8125, 0.9062, 0.8125, 0.8750, 0.8750, 0.9062, 0.8750, 0.9062, 0.9062, 0.8125]

test_accuracy_values = [0.5938, 0.7188, 0.5938, 0.6875, 0.6562, 0.6875, 0.7188, 0.7188, 0.7500, 0.6875,
                        0.7188, 0.6875, 0.6875, 0.7500, 0.7188, 0.6875, 0.7188, 0.6875, 0.7188, 0.7188,
                        0.7500, 0.7188, 0.7500, 0.7188, 0.7188, 0.7188, 0.7188, 0.6875, 0.7500, 0.7188,
                        0.7188, 0.7500, 0.7188, 0.7500, 0.7188, 0.7188, 0.7188, 0.6875, 0.7188, 0.7500,
                        0.7500, 0.7188, 0.7188, 0.7500, 0.7500, 0.7500, 0.7188, 0.7188, 0.7500, 0.7188,
                        0.7500, 0.7500, 0.7188, 0.7500, 0.7188, 0.7500, 0.7188, 0.7188, 0.7188, 0.7500,
                        0.7500, 0.7500, 0.7188, 0.7500, 0.7188, 0.7500, 0.7188, 0.7188, 0.7500, 0.7500,
                        0.7188, 0.7500, 0.7500, 0.7188, 0.7500, 0.7500, 0.7188, 0.7500, 0.7500, 0.7188,
                        0.7500, 0.7500, 0.7188, 0.7500, 0.7188, 0.7188, 0.7188, 0.7500, 0.7500, 0.7188,
                        0.7500, 0.7500, 0.7188, 0.7500, 0.7188, 0.7500, 0.7500, 0.7188, 0.7500, 0.7500,
                        0.7188, 0.7500, 0.7188, 0.7500, 0.7500, 0.7500, 0.7188, 0.7188, 0.7188, 0.7500,
                        0.7500, 0.7188, 0.7188, 0.7500, 0.7188, 0.7500, 0.7500, 0.7188, 0.7500, 0.7500]
if __name__ == '__main__':

    # Create subplots
    fig, axs = plt.subplots(2, 1, figsize=(12, 10))

    # Plot training and testing losses
    axs[0].plot(train_loss_values, label='Training Loss')
    axs[0].plot(test_loss_values, label='Testing Loss')
    axs[0].set_title('Training and Testing Loss Over Training Steps')
    axs[0].set_xlabel('Steps')
    axs[0].set_ylabel('Loss')
    axs[0].legend()

    # Plot training and testing accuracies
    axs[1].plot(train_accuracy_values, label='Training Accuracy')
    axs[1].plot(test_accuracy_values, label='Testing Accuracy')
    axs[1].set_title('Training and Testing Accuracy Over Training Steps')
    axs[1].set_xlabel('Steps')
    axs[1].set_ylabel('Accuracy')
    axs[1].legend()

    plt.tight_layout()
    plt.show()
